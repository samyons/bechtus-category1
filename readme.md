# AAOIFI Standards CoVe RAG Assistant with Streamlit

This application uses a Retrieval Augmented Generation (RAG) pipeline enhanced with a Chain-of-Verification (CoVe) process to answer questions about AAOIFI (Accounting and Auditing Organization for Islamic Financial Institutions) standards. It leverages Google's Gemini models and ChromaDB for vector storage.

## Features
- Loads AAOIFI standards from PDF documents.
- Chunks documents and creates a vector store using ChromaDB.
- Implements a Chain-of-Verification (CoVe) pipeline:
    1. Generates a draft answer.
    2. Plans verification questions based on the draft.
    3. Independently answers verification questions (with targeted RAG).
    4. Revises the draft into a final, verified answer.
- Streamlit interface for user interaction and displaying the CoVe process.

## Project Structure

aaoifi_cove_streamlit_app/
├── .env # For API key (YOU CREATE THIS)
├── .gitignore
├── README.md
├── requirements.txt # Python dependencies
├── app.py # Main Streamlit application
│
├── core/ # Core CoVe logic
│ ├── init.py
│ ├── cove_pipeline.py
│ └── llm_prompts.py
│
├── data_processing/ # Document handling & vector store
│ ├── init.py
│ ├── document_loader.py
│ └── vector_store.py
│
└── aaoifi_pdfs/ # Add your 10 AAOIFI PDF files here
├── FAS_4.pdf
└── ...


1.  **Clone the Repository (or create the structure):**
    ```bash
    # If you have it on GitHub:
    # git clone [your-repo-url]
    # cd aaoifi_cove_streamlit_app
    ```

2.  **Create a Virtual Environment (Recommended):**
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # On Windows: .venv\Scripts\activate
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Create `.env` File:**
    In the root of the `aaoifi_cove_streamlit_app` directory, create a file named `.env` and add your Google Gemini API key:
    ```
    GOOGLE_API_KEY="YOUR_ACTUAL_GEMINI_API_KEY"
    ```

5.  **Add AAOIFI PDF Documents:**
    Create a directory named `aaoifi_pdfs` in the root of the project. Place your 10 AAOIFI standard PDF files (5 FAS, 5 SS) into this directory.

## Running the Application

1.  **Ensure your virtual environment is activated.**
2.  **Navigate to the project root directory (`aaoifi_cove_streamlit_app/`).**
3.  **Run the Streamlit app:**
    ```bash
    streamlit run app.py
    ```
    This will open the application in your web browser.

## How it Works

-   **Data Processing:** PDFs in `aaoifi_pdfs/` are loaded, chunked, and embedded. These embeddings are stored in a persistent ChromaDB vector store located in `chroma_db_store/`.
-   **CoVe Pipeline:**
    -   When a user submits a scenario and question, the system first retrieves relevant context from the vector store.
    -   An initial draft answer is generated by the LLM.
    -   The LLM then plans verification questions to check the draft's factual claims.
    -   Each verification question triggers a new, targeted RAG lookup to find specific evidence. The LLM answers these verification questions.
    -   Finally, the LLM revises the initial draft answer based on the verification outcomes, producing a more robust and factually grounded final answer.
-   **Streamlit UI:** Provides an interface to input scenarios/questions and displays the draft answer, verification steps, and the final verified answer.

## Customization
-   **LLM Model:** The `LLM_MODEL_NAME` in `core/cove_pipeline.py` can be changed to other compatible Gemini models.
-   **Chunking Strategy:** Parameters in `data_processing/document_loader.py` can be adjusted.
-   **Prompts:** All prompts are centralized in `core/llm_prompts.py` for easier modification.
-   **Vector Store:** ChromaDB settings are in `data_processing/vector_store.py`.